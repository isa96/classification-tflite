# -*- coding: utf-8 -*-
"""MODEL_DEPLOYMENT_DICODING_FELIX_PRATAMASAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cZmzQDTk3rCQYWWIBP6psUJuwTTAP8Xm

# NAMA: FELIX PRATAMASAN
# EMAIL: felixpratama242@gmail.com
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import zipfile
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
from keras.callbacks import EarlyStopping
import seaborn as sns
import pathlib
# %matplotlib inline

"""# Download Data"""

#you need to create your own API first in kaggle
#upload kaggle json

files.upload()

#create a kaggle folder
!mkdir ~/.kaggle

#copy kaggle.json to folder created
!cp kaggle.json ~/.kaggle/

#permission for the json to act
! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d puneet6060/intel-image-classification

"""#Read Dataset"""

test_local_zip = '/content/intel-image-classification.zip'
zip_ref = zipfile.ZipFile(test_local_zip, 'r')
zip_ref.extractall('/content/dataset')

zip_ref.close()

train_dir = '/content/dataset/seg_train/seg_train'
# test_dir = '/content/dataset/seg_test/seg_test'

print('Num of classes: {}, there are: {}'.format(len(os.listdir(train_dir)), os.listdir(train_dir)))

train_classes = []
# test_classes = []

for index in range(len(os.listdir(train_dir))):
  classes = os.path.join(train_dir, os.listdir(train_dir)[index])
  len_class = len(os.listdir(classes))
  train_classes.append(len_class)


# for index in range(len(os.listdir(test_dir))):
#   classes = os.path.join(test_dir, os.listdir(test_dir)[index])
#   len_class = len(os.listdir(classes))
#   test_classes.append(len_class)

print("total images in train dir: {}".format(sum(train_classes)))
sns.barplot(x=os.listdir(train_dir), y = train_classes).set(title='Images in Train Dir')
plt.show()

# print("total images in test dir: {}".format(sum(test_classes)))
# sns.barplot(x=os.listdir(test_dir), y = test_classes).set(title='Images in Test Dir')
# plt.show()

# Show sample images for each classes

fig = plt.figure(figsize = (18,10))

for index in range (len(os.listdir(train_dir))):
  dir = os.path.join(train_dir, os.listdir(train_dir)[index])
  img = cv2.imread(os.path.join(dir, os.listdir(dir)[0]))
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  
  ax = fig.add_subplot(2,3,index+1)
  ax.imshow(img)
  ax.set_title(os.listdir(train_dir)[index])

"""# Data Preprocessing"""

train_generator = ImageDataGenerator(rescale = 1./255,
                                      rotation_range=20,
                                      horizontal_flip=True,
                                      vertical_flip=True,
                                      shear_range = 0.2,
                                      zoom_range = 0.2,
                                      fill_mode = 'nearest',
                                      validation_split = 0.2)

# valid_generator = ImageDataGenerator(rescale=1./255)

train_datagen = train_generator.flow_from_directory(train_dir,
                                                    batch_size = 20,
                                                    target_size= (150,150),
                                                    class_mode = 'categorical',
                                                    subset='training')

test_datagen = train_generator.flow_from_directory(train_dir,
                                                    batch_size = 16,
                                                    target_size= (150,150),
                                                    class_mode = 'categorical',
                                                   subset='validation')

"""# Build and Train Model"""

model = Sequential()
# model.add(tf.keras.applications.InceptionV3(input_shape=(150,150,3), weights='imagenet', include_top=False ))
model.add(Conv2D(128, 5, input_shape=(150,150,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Conv2D(256, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Conv2D(256, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
# model.add(Dropout(0.5))
model.add(Conv2D(512, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(1024, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(512, activation='relu'))
model.add(Dense(6, activation='softmax'))

model.summary()

callback = EarlyStopping(monitor = 'val_loss',
                        patience = 3,
                        verbose = 1)

model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(train_datagen,
          # steps_per_epoch= 128,
          validation_data = test_datagen,
          callbacks = [callback],
          epochs= 50,
          verbose =1)

# Plot the training and validation accuracies for each epoch

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

fig = plt.figure(figsize = (15,5))
ax1 = fig.add_subplot(1,2,1)
ax2 = fig.add_subplot(1,2,2)


ax1.plot(epochs, acc, 'r', label='Training accuracy')
ax1.plot(epochs, val_acc, 'b', label='Validation accuracy')
ax1.set_title('Training and validation accuracy')
ax1.legend(loc=0)


ax2.plot(epochs, loss, 'r', label='Training loss')
ax2.plot(epochs, val_loss, 'b', label='Validation loss')
ax2.set_title('Training and validation loss')
ax2.legend(loc=0)


plt.show()

"""# Save Model"""

export_dir = 'saved_model/'
tf.saved_model.save(model, export_dir)
 
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
 
tflite_model_file = pathlib.Path('model.tflite')
tflite_model_file.write_bytes(tflite_model)